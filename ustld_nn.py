# -*- coding: utf-8 -*-
"""USTLD NN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10DYT5cVuJX1XxgwcafrRE5RBEzEN37UV
"""

# MLP with automatic validation set
import pandas
import numpy as np
from sklearn.preprocessing import LabelEncoder
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold 
from sklearn.model_selection import cross_val_score
import math 
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
import numpy

dataframe = pandas.read_excel('Test1 (1).xlsx') 
dataframe.tail()



# split into input (X) and output (Y) variables
X = np.array(dataframe.drop(['Fitness'],1)) #.astype(int)
#X = np.array(dataframe.drop(['Friquency','Tx Height','AoA','Path Loss'],1))

# Assigning the target data into (y)

y = np.array(dataframe['Fitness'])
X.shape, y.shape

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler 

X = np.array(dataframe.drop(['Fitness'],1))
y = np.array(dataframe['Fitness'])
scaler = MinMaxScaler(feature_range=(0,1))
X = scaler.fit_transform(np.array(X).reshape(-1,1))
X = X.reshape(y.shape[0],16)
y = scaler.fit_transform(np.array(y).reshape(-1,1))


print(X.shape)
print(y.shape)

#spilit data 
from sklearn.model_selection import train_test_split

X_train, X_test , y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle=True)

X_train.shape, y_train.shape

## ANN model
import tensorflow as tf
from tensorflow import keras 


model = keras.Sequential([
    
    keras.layers.Dense(96, input_shape = (16,), activation='relu'),
    keras.layers.Dense(96, activation='relu'),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(1, activation='linear'),
])
optimizer = keras.optimizers.Adam(learning_rate=0.0001)
model.compile(loss='mean_squared_error', optimizer=optimizer)

model.summary()

from sklearn.metrics import r2_score
 
kf = KFold(n_splits=7, random_state=30, shuffle=True)
scores = []
r_square = []
rmse = []
MAPE = []
mse = []
corr = []
for i, (train_index, test_index) in enumerate(kf.split(X)):
    X_train = X[train_index,:]
    y_train = y[train_index]
    X_test = X[test_index,:]
    y_test = y[test_index]

    # fit the model with the training data
    
    history = model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=100, verbose=1)
    
    
    y_pred = model.predict(X_test)
    
    r = r2_score(y_pred,y_test)
    r_square.append(round(r, 6))
    
    from sklearn.metrics import mean_squared_error
    ### Test Data RMSE
    rmse_prediction = math.sqrt(mean_squared_error(y_test,y_pred))
    rmse.append(round(rmse_prediction, 6))
    
    from sklearn.metrics import mean_absolute_percentage_error
    from sklearn.utils.validation import check_consistent_length, check_array
    MAPE_value = mean_absolute_percentage_error(y_pred,y_test)
    MAPE.append(round(MAPE_value,6))
    
    mse_value = mean_squared_error(y_test,y_pred)
    mse.append(round(mse_value,6))
    
    '''Running the example calculates and prints the Pearsonâ€™s correlation coefficient.
            We can see that the two variables are positively correlated and that the correlation is 0.8.
            This suggests a high level of correlation, e.g. a value above 0.5 and close to 1.0.'''
    
    from scipy.stats import pearsonr
    corr_value, _ = pearsonr(y_test.flatten(), y_pred.flatten())
    corr.append(round(corr_value,6))


#print('R^2 Square:', scores)
#print(min(scores), round(np.mean(scores),6), max(scores))
print('R^2 Square:', r_square)
print(min(r_square), round(np.mean(r_square),6), max(r_square))

print('Root Mean Square Error:', rmse)
print(min(rmse), round(np.mean(rmse),6), max(rmse))

print('Mean Absolute Percentage Error:', MAPE)
print(min(MAPE), round(np.mean(MAPE),6), max(MAPE))

print('Mean Square Error:',mse)
print(min(mse), round(np.mean(mse),6), max(mse))

print('Pearsons correlation:', corr)
print(min(corr), round(np.mean(corr),6), max(corr))

model.save("USTLD_model2.h5")

#spilit data 
from sklearn.model_selection import train_test_split

pred = model.predict(X)
pred_ann = model.predict(X_test)
pred_ann = scaler.inverse_transform(pred_ann)
y = scaler.inverse_transform(y_test)

import matplotlib.pyplot as plt 


plt.style.use('fivethirtyeight')
plt.figure(figsize=(16,8))
plt.scatter(y,pred_ann, marker='D')
plt.xlabel('Actual Values')
plt.ylabel('Predicted Values')
#plt.savefig('C:/Users/CL/Pictures/PathLoss/ann_img6.png', dpi=500,bbox_inches='tight')
plt.show()
#plt.title('Path Loss')



